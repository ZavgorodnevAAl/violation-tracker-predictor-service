{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1e2ad0ee-ad17-431b-82c4-97865e8aaf20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:46:59.751456Z",
     "iopub.status.busy": "2024-05-31T12:46:59.750061Z",
     "iopub.status.idle": "2024-05-31T12:46:59.779001Z",
     "shell.execute_reply": "2024-05-31T12:46:59.777989Z",
     "shell.execute_reply.started": "2024-05-31T12:46:59.751405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pytorch_lightning\n",
    "import pytorchvideo.data\n",
    "import torch.utils.data\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomRotation\n",
    ")\n",
    "\n",
    "import os \n",
    "import csv\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from torchvision.transforms._transforms_video import NormalizeVideo\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from ipywidgets import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1056f67-b8d1-414e-b130-ad6779dbae4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T16:40:45.043796Z",
     "iopub.status.busy": "2024-05-31T16:40:45.042297Z",
     "iopub.status.idle": "2024-05-31T16:40:45.107177Z",
     "shell.execute_reply": "2024-05-31T16:40:45.105933Z",
     "shell.execute_reply.started": "2024-05-31T16:40:45.043739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:              94           1          90           0           1          91\n",
      "Swap:              0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d45bca87-4e8d-4784-881b-b1ab1bb82203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:47:01.112278Z",
     "iopub.status.busy": "2024-05-31T12:47:01.110833Z",
     "iopub.status.idle": "2024-05-31T12:47:01.180028Z",
     "shell.execute_reply": "2024-05-31T12:47:01.178851Z",
     "shell.execute_reply.started": "2024-05-31T12:47:01.112231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e259af4-ebe1-4709-bafb-1c8d6308f7d1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-31T14:00:39.685241636Z",
     "iopub.status.idle": "2024-05-31T14:00:39.685935210Z",
     "shell.execute_reply": "2024-05-31T14:00:39.685201214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Unknown instance spec",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "num_frames = 30\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "\n",
    "clip_duration = (num_frames * sampling_rate) / frames_per_second\n",
    "\n",
    "video_transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=T.Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames), \n",
    "            T.Lambda(lambda x: x / 255.0),  \n",
    "            ShortSideScale(size=256),\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            NormalizeVideo(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            # RandomRotation(10)\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4b51468b-3b23-4b5e-ad1f-103caf1776f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:54:41.768991Z",
     "iopub.status.busy": "2024-05-31T12:54:41.767562Z",
     "iopub.status.idle": "2024-05-31T12:54:41.806511Z",
     "shell.execute_reply": "2024-05-31T12:54:41.805412Z",
     "shell.execute_reply.started": "2024-05-31T12:54:41.768935Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_path = \"data/train/2_5395803543229709261.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fce95a84-3446-40d8-8658-bae4c16e96b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T13:14:02.790210Z",
     "iopub.status.busy": "2024-05-31T13:14:02.788869Z",
     "iopub.status.idle": "2024-05-31T13:14:02.934036Z",
     "shell.execute_reply": "2024-05-31T13:14:02.932815Z",
     "shell.execute_reply.started": "2024-05-31T13:14:02.790153Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "int(video.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a1bbaa3e-19c0-4384-9642-2ff1654a2090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T13:02:52.754885Z",
     "iopub.status.busy": "2024-05-31T13:02:52.753491Z",
     "iopub.status.idle": "2024-05-31T13:02:55.610244Z",
     "shell.execute_reply": "2024-05-31T13:02:55.609085Z",
     "shell.execute_reply.started": "2024-05-31T13:02:52.754846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': tensor([[[[  9.,   9.,   9.,  ...,  46.,  47.,  47.],\n",
      "          [  9.,   9.,   9.,  ...,  47.,  48.,  48.],\n",
      "          [  9.,   9.,   9.,  ...,  53.,  53.,  53.],\n",
      "          ...,\n",
      "          [122., 132., 123.,  ...,  57.,  61.,  64.],\n",
      "          [131., 142., 132.,  ...,  56.,  58.,  62.],\n",
      "          [136., 146., 137.,  ...,  54.,  57.,  61.]],\n",
      "\n",
      "         [[  9.,   9.,   9.,  ...,  62.,  62.,  64.],\n",
      "          [  9.,   9.,   9.,  ...,  64.,  66.,  67.],\n",
      "          [  9.,   9.,   9.,  ...,  78.,  82.,  82.],\n",
      "          ...,\n",
      "          [ 58.,  54.,  49.,  ...,  80.,  75.,  80.],\n",
      "          [ 81.,  86.,  69.,  ..., 100.,  70.,  65.],\n",
      "          [ 94.,  90.,  55.,  ...,  93.,  73.,  48.]],\n",
      "\n",
      "         [[ 66.,  71.,  68.,  ...,  54.,  57.,  55.],\n",
      "          [ 63.,  66.,  64.,  ...,  54.,  57.,  55.],\n",
      "          [ 57.,  59.,  59.,  ...,  54.,  57.,  55.],\n",
      "          ...,\n",
      "          [ 54.,  69.,  68.,  ...,  15.,  15.,  15.],\n",
      "          [ 63., 105.,  81.,  ...,  15.,  17.,  17.],\n",
      "          [ 39.,  66.,  70.,  ...,  15.,  17.,  17.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 13.,  13.,  17.,  ...,  37.,  37.,  37.],\n",
      "          [ 16.,  16.,  20.,  ...,  37.,  37.,  37.],\n",
      "          [ 21.,  21.,  24.,  ...,  37.,  37.,  37.],\n",
      "          ...,\n",
      "          [186., 186., 186.,  ..., 103., 101., 107.],\n",
      "          [186., 186., 186.,  ...,  85.,  75.,  72.],\n",
      "          [186., 186., 186.,  ...,  66.,  48.,  44.]],\n",
      "\n",
      "         [[ 32.,  37.,  45.,  ...,  38.,  38.,  38.],\n",
      "          [ 32.,  37.,  45.,  ...,  38.,  38.,  38.],\n",
      "          [ 34.,  38.,  44.,  ...,  38.,  38.,  38.],\n",
      "          ...,\n",
      "          [166., 166., 164.,  ..., 136., 136., 136.],\n",
      "          [166., 166., 163.,  ...,  95.,  95.,  95.],\n",
      "          [166., 166., 163.,  ...,  73.,  73.,  73.]],\n",
      "\n",
      "         [[ 32.,  37.,  45.,  ...,  38.,  38.,  38.],\n",
      "          [ 32.,  37.,  45.,  ...,  38.,  38.,  38.],\n",
      "          [ 34.,  38.,  44.,  ...,  38.,  38.,  38.],\n",
      "          ...,\n",
      "          [171., 173., 170.,  ...,  81.,  81.,  62.],\n",
      "          [144., 146., 146.,  ...,  89.,  93.,  86.],\n",
      "          [130., 132., 136.,  ...,  90.,  92.,  92.]]],\n",
      "\n",
      "\n",
      "        [[[  6.,   6.,   6.,  ..., 138., 139., 139.],\n",
      "          [  6.,   6.,   6.,  ..., 139., 140., 140.],\n",
      "          [  6.,   6.,   6.,  ..., 145., 145., 145.],\n",
      "          ...,\n",
      "          [132., 142., 133.,  ...,  50.,  54.,  57.],\n",
      "          [141., 152., 142.,  ...,  49.,  51.,  55.],\n",
      "          [146., 156., 147.,  ...,  47.,  50.,  54.]],\n",
      "\n",
      "         [[  6.,   6.,   7.,  ..., 137., 137., 139.],\n",
      "          [  6.,   6.,   7.,  ..., 139., 141., 142.],\n",
      "          [  6.,   6.,   7.,  ..., 148., 152., 152.],\n",
      "          ...,\n",
      "          [ 59.,  55.,  50.,  ...,  73.,  68.,  73.],\n",
      "          [ 82.,  87.,  70.,  ...,  93.,  63.,  58.],\n",
      "          [ 95.,  91.,  56.,  ...,  86.,  66.,  41.]],\n",
      "\n",
      "         [[ 55.,  60.,  57.,  ..., 152., 151., 149.],\n",
      "          [ 52.,  55.,  53.,  ..., 152., 151., 149.],\n",
      "          [ 46.,  48.,  48.,  ..., 152., 151., 149.],\n",
      "          ...,\n",
      "          [ 57.,  72.,  71.,  ...,   8.,   8.,   8.],\n",
      "          [ 66., 108.,  84.,  ...,   8.,   7.,   7.],\n",
      "          [ 42.,  69.,  73.,  ...,   8.,   7.,   7.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 25.,  25.,  29.,  ..., 114., 114., 114.],\n",
      "          [ 28.,  28.,  32.,  ..., 114., 114., 114.],\n",
      "          [ 32.,  32.,  35.,  ..., 114., 114., 114.],\n",
      "          ...,\n",
      "          [186., 186., 186.,  ..., 102., 100., 106.],\n",
      "          [186., 186., 186.,  ...,  84.,  74.,  71.],\n",
      "          [186., 186., 186.,  ...,  65.,  47.,  43.]],\n",
      "\n",
      "         [[ 32.,  37.,  45.,  ..., 112., 112., 112.],\n",
      "          [ 32.,  37.,  45.,  ..., 112., 112., 112.],\n",
      "          [ 34.,  38.,  44.,  ..., 112., 112., 112.],\n",
      "          ...,\n",
      "          [176., 176., 174.,  ..., 135., 135., 135.],\n",
      "          [176., 176., 173.,  ...,  94.,  94.,  94.],\n",
      "          [176., 176., 173.,  ...,  72.,  72.,  72.]],\n",
      "\n",
      "         [[ 32.,  37.,  45.,  ..., 112., 112., 112.],\n",
      "          [ 32.,  37.,  45.,  ..., 112., 112., 112.],\n",
      "          [ 34.,  38.,  44.,  ..., 112., 112., 112.],\n",
      "          ...,\n",
      "          [181., 183., 180.,  ...,  77.,  77.,  58.],\n",
      "          [154., 156., 156.,  ...,  88.,  89.,  82.],\n",
      "          [140., 142., 146.,  ...,  89.,  88.,  88.]]],\n",
      "\n",
      "\n",
      "        [[[ 21.,  21.,  21.,  ..., 230., 231., 231.],\n",
      "          [ 21.,  21.,  21.,  ..., 231., 232., 232.],\n",
      "          [ 21.,  21.,  21.,  ..., 237., 237., 237.],\n",
      "          ...,\n",
      "          [138., 148., 139.,  ...,  48.,  52.,  55.],\n",
      "          [147., 158., 148.,  ...,  47.,  49.,  53.],\n",
      "          [152., 162., 153.,  ...,  45.,  48.,  52.]],\n",
      "\n",
      "         [[ 21.,  21.,  17.,  ..., 232., 232., 234.],\n",
      "          [ 21.,  21.,  17.,  ..., 234., 236., 237.],\n",
      "          [ 21.,  21.,  17.,  ..., 220., 224., 224.],\n",
      "          ...,\n",
      "          [ 78.,  74.,  69.,  ...,  71.,  66.,  71.],\n",
      "          [101., 106.,  89.,  ...,  91.,  61.,  56.],\n",
      "          [114., 110.,  75.,  ...,  84.,  64.,  39.]],\n",
      "\n",
      "         [[ 62.,  67.,  64.,  ..., 233., 233., 231.],\n",
      "          [ 59.,  62.,  60.,  ..., 233., 233., 231.],\n",
      "          [ 55.,  57.,  57.,  ..., 233., 233., 231.],\n",
      "          ...,\n",
      "          [ 75.,  90.,  91.,  ...,  11.,  11.,  11.],\n",
      "          [ 84., 126., 104.,  ...,  11.,  11.,  11.],\n",
      "          [ 60.,  87.,  93.,  ...,  11.,  11.,  11.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 31.,  31.,  35.,  ..., 195., 195., 195.],\n",
      "          [ 34.,  34.,  38.,  ..., 195., 195., 195.],\n",
      "          [ 33.,  33.,  36.,  ..., 195., 195., 195.],\n",
      "          ...,\n",
      "          [198., 198., 198.,  ..., 107., 103., 109.],\n",
      "          [198., 198., 198.,  ...,  87.,  77.,  74.],\n",
      "          [198., 198., 198.,  ...,  68.,  50.,  46.]],\n",
      "\n",
      "         [[ 32.,  37.,  45.,  ..., 203., 203., 203.],\n",
      "          [ 32.,  37.,  45.,  ..., 203., 203., 203.],\n",
      "          [ 34.,  38.,  44.,  ..., 203., 203., 203.],\n",
      "          ...,\n",
      "          [184., 184., 182.,  ..., 128., 128., 128.],\n",
      "          [184., 184., 181.,  ...,  87.,  87.,  87.],\n",
      "          [184., 184., 181.,  ...,  65.,  65.,  65.]],\n",
      "\n",
      "         [[ 32.,  37.,  45.,  ..., 203., 203., 203.],\n",
      "          [ 32.,  37.,  45.,  ..., 203., 203., 203.],\n",
      "          [ 34.,  38.,  44.,  ..., 203., 203., 203.],\n",
      "          ...,\n",
      "          [189., 191., 188.,  ...,  71.,  71.,  52.],\n",
      "          [162., 164., 164.,  ...,  79.,  83.,  76.],\n",
      "          [148., 150., 154.,  ...,  80.,  82.,  82.]]]]), 'audio': None}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an EncodedVideo helper class\n",
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "video\n",
    "# Load the desired clip and specify the start and end duration.\n",
    "# The start_sec should correspond to where the action occurs in the video\n",
    "video_data = video.get_clip(start_sec=0, end_sec=2.0)\n",
    "\n",
    "# Apply a transform to normalize the video input\n",
    "video_data = video_transform(video_data)\n",
    "\n",
    "# Move the inputs to the desired device\n",
    "video_inputs = video_data[\"video\"]\n",
    "\n",
    "# Take the first clip \n",
    "# The model expects inputs of shape: B x C x T x H x W\n",
    "video_input = video_inputs[0][None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1629813a-7f44-46b5-9152-e0792879fc8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:56:57.117490Z",
     "iopub.status.busy": "2024-05-31T12:56:57.116160Z",
     "iopub.status.idle": "2024-05-31T12:56:57.133105Z",
     "shell.execute_reply": "2024-05-31T12:56:57.131898Z",
     "shell.execute_reply.started": "2024-05-31T12:56:57.117453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 160, 256, 455])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7bd6221a-7620-4d9a-ba86-50d7a0411fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:54:56.698674Z",
     "iopub.status.busy": "2024-05-31T12:54:56.697342Z",
     "iopub.status.idle": "2024-05-31T12:54:56.716959Z",
     "shell.execute_reply": "2024-05-31T12:54:56.715793Z",
     "shell.execute_reply.started": "2024-05-31T12:54:56.698637Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(video_inputs).transpose((1, 2, 3, 0))[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bb2a2c15-82b6-4ccb-a0c1-bbd8f8198fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:54:33.015201Z",
     "iopub.status.busy": "2024-05-31T12:54:33.013991Z",
     "iopub.status.idle": "2024-05-31T12:54:33.029985Z",
     "shell.execute_reply": "2024-05-31T12:54:33.028837Z",
     "shell.execute_reply.started": "2024-05-31T12:54:33.015161Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KineticsDataModule(pytorch_lightning.LightningDataModule):\n",
    "    _DATA_PATH = \"data\"\n",
    "    _CLIP_DURATION = 2\n",
    "    _BATCH_SIZE = 8\n",
    "    _NUM_WORKERS = 8\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_transform = ApplyTransformToKey(\n",
    "            key=\"video\",\n",
    "            transform=T.Compose(\n",
    "                [\n",
    "                    UniformTemporalSubsample(num_frames), \n",
    "                    T.Lambda(lambda x: x / 255.0),  \n",
    "                    ShortSideScale(size=256),\n",
    "                    RandomHorizontalFlip(p=0.5),\n",
    "                    NormalizeVideo(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    # RandomRotation(10)\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        train_dataset = pytorchvideo.data.Kinetics(\n",
    "            data_path=os.path.join(self._DATA_PATH, \"train.csv\"),\n",
    "            clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\", self._CLIP_DURATION),\n",
    "            transform=train_transform\n",
    "        )\n",
    "        return torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self._BATCH_SIZE,\n",
    "            num_workers=self._NUM_WORKERS,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452be7b5-74fd-4a62-866d-1ed837c8b1de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:07:07.032680Z",
     "iopub.status.busy": "2024-05-31T12:07:07.031518Z",
     "iopub.status.idle": "2024-05-31T12:07:07.051827Z",
     "shell.execute_reply": "2024-05-31T12:07:07.050692Z",
     "shell.execute_reply.started": "2024-05-31T12:07:07.032641Z"
    }
   },
   "outputs": [],
   "source": [
    "module = KineticsDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ae0fe-53fb-4635-896a-060c523c767f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:07:51.600273Z",
     "iopub.status.busy": "2024-05-31T12:07:51.599186Z",
     "iopub.status.idle": "2024-05-31T12:07:52.409454Z",
     "shell.execute_reply": "2024-05-31T12:07:52.407597Z",
     "shell.execute_reply.started": "2024-05-31T12:07:51.600226Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data/train.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4175/2531642804.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4175/950523415.py\u001b[0m in \u001b[0;36mtrain_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m             ]\n\u001b[1;32m     24\u001b[0m         )\n\u001b[0;32m---> 25\u001b[0;31m         train_dataset = pytorchvideo.data.Kinetics(\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mclip_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytorchvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_clip_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CLIP_DURATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorchvideo/data/kinetics.py\u001b[0m in \u001b[0;36mKinetics\u001b[0;34m(data_path, clip_sampler, video_sampler, transform, video_path_prefix, decode_audio, decoder)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PYTORCHVIDEO.dataset.Kinetics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     return labeled_video_dataset(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mclip_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorchvideo/data/labeled_video_dataset.py\u001b[0m in \u001b[0;36mlabeled_video_dataset\u001b[0;34m(data_path, clip_sampler, video_sampler, transform, video_path_prefix, decode_audio, decoder)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mlabeled_video_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabeledVideoPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0mlabeled_video_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_path_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     dataset = LabeledVideoDataset(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorchvideo/data/labeled_video_paths.py\u001b[0m in \u001b[0;36mfrom_path\u001b[0;34m(cls, data_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLabeledVideoPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: data/train.csv not found."
     ]
    }
   ],
   "source": [
    "tdl = module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "592e4504-fc27-409e-b5ae-ea6c0b7e3608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:05:34.193631Z",
     "iopub.status.busy": "2024-05-31T12:05:34.192432Z",
     "iopub.status.idle": "2024-05-31T12:05:34.207505Z",
     "shell.execute_reply": "2024-05-31T12:05:34.206327Z",
     "shell.execute_reply.started": "2024-05-31T12:05:34.193579Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorchvideo.models.resnet\n",
    "\n",
    "def make_kinetics_resnet():\n",
    "  return pytorchvideo.models.resnet.create_resnet(\n",
    "      input_channel=3, # RGB input from Kinetics\n",
    "      model_depth=50, # For the tutorial let's just use a 50 layer network\n",
    "      model_num_class=2,\n",
    "      norm=nn.BatchNorm3d,\n",
    "      activation=nn.ReLU,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4f1d76-3727-4f6f-ae67-8c97fa6e2cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:00:59.944282Z",
     "iopub.status.busy": "2024-05-31T12:00:59.942631Z",
     "iopub.status.idle": "2024-05-31T12:00:59.966798Z",
     "shell.execute_reply": "2024-05-31T12:00:59.965816Z",
     "shell.execute_reply.started": "2024-05-31T12:00:59.944229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VideoClassificationLightningModule(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = make_kinetics_resnet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # The model expects a video tensor of shape (B, C, T, H, W), which is the\n",
    "        # format provided by the dataset\n",
    "        y_hat = self.model(batch[\"video\"])\n",
    "\n",
    "        # Compute cross entropy loss, loss.backwards will be called behind the scenes\n",
    "        # by PyTorchLightning after being returned from this method.\n",
    "        loss = F.cross_entropy(y_hat, batch[\"label\"])\n",
    "\n",
    "        # Log the train loss to Tensorboard\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self.model(batch[\"video\"])\n",
    "        loss = F.cross_entropy(y_hat, batch[\"label\"])\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Setup the Adam optimizer. Note, that this function also can return a lr scheduler, which is\n",
    "        usually useful for training video models.\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a74878-7e31-4ad8-b8ed-cb89c8684a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:01:32.306744Z",
     "iopub.status.busy": "2024-05-31T12:01:32.305275Z",
     "iopub.status.idle": "2024-05-31T12:01:32.321513Z",
     "shell.execute_reply": "2024-05-31T12:01:32.320397Z",
     "shell.execute_reply.started": "2024-05-31T12:01:32.306688Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    classification_module = VideoClassificationLightningModule()\n",
    "    data_module = KineticsDataModule()\n",
    "    trainer = pytorch_lightning.Trainer()\n",
    "    trainer.fit(classification_module, data_module)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c56b4-1ec8-4905-bbc4-4d56948963d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
